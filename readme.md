# Biped RL in PyBullet

ü¶µ Biped RL in PyBullet ‚Äî Generaliza√ß√£o Cruzada
Este projeto implementa um framework para treinar e avaliar agentes de Aprendizado por Refor√ßo (RL) no controle de um rob√¥ b√≠pede em simula√ß√£o f√≠sica (PyBullet). O foco √© estudar a generaliza√ß√£o cruzada de pol√≠ticas treinadas em diferentes ambientes perturbados.

Atualmente, o sistema est√° na Semana 2: Valida√ß√£o do Pipeline de Treinamento, com infraestrutura completa para simula√ß√£o, logging, interface gr√°fica e registro de m√©tricas.

# Objetivo Geral

Treinar 6 agentes especialistas (AE), cada um em um circuito distinto (PR, P<Œº, RamA, RamD, PG, PRB), e avaliar sua capacidade de generaliza√ß√£o quando testados nos outros 5 circuitos. A m√©trica principal √© o Tempo M√©dio (Tm) para completar os 10 metros.

## Installation

### Install Python

This project is being developped with python 3.12.7.

### Clone the repository

```
git clone https://github.com/jonattanc/phd-biped-rl.git
cd phd-biped-rl
```

### Create a virtual environment

```
python -m venv .venv
source .venv/bin/activate # Linux/macOS
.venv\Scripts\activate # Windows
```

### Install dependencies

```
pip install pybullet xacrodoc numpy matplotlib
pip install stable-baselines3[extra] gym==0.23.1 tensorboard
```

### Setup the development environment

It's recommended to use Visual Studio Code with the Python extension. This should be enough to activate the Black lint extension when saving files.

## Usage

### Activate the virtual environment

```
source .venv/bin/activate # Linux/macOS
.venv\Scripts\activate # Windows
```

### Run

```
python main.py
```

### Interface Gr√°fica
Inicie o Treinamento: Selecione "PR" e "robot_stage1", clique em "Iniciar Treinamento".
Monitore em Tempo Real: Gr√°ficos de Recompensa, Dura√ß√£o e Dist√¢ncia por epis√≥dio.
Controle: Pausar, Finalizar, Salvar Snapshot (metadados).
Logs: A caixa de texto exibe os logs mais recentes.

### Estrutura de Arquivos
phd-biped-rl/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.py        # Ponto de entrada. Inicializa a GUI.
‚îÇ   ‚îú‚îÄ‚îÄ gui.py         # Interface Tkinter + Gr√°ficos Matplotlib + Logger integrado.
‚îÇ   ‚îú‚îÄ‚îÄ agent.py       # Classe Agent. A√ß√µes aleat√≥rias (placeholder para PPO).
‚îÇ   ‚îú‚îÄ‚îÄ environment.py # Classe Environment. Carrega .xacro de ambientes.
‚îÇ   ‚îú‚îÄ‚îÄ gym_env.py     # Ambiente no padr√£o gym. Implementa step e reset.
‚îÇ   ‚îú‚îÄ‚îÄ metrics_saver.py  # Calcula m√©tricas estatisticas e salva.
‚îÇ   ‚îú‚îÄ‚îÄ robot.py       # Classe Robot. Carrega .xacro, obt√©m juntas.
‚îÇ   ‚îú‚îÄ‚îÄ simulation.py  # L√≥gica principal de simula√ß√£o e c√°lculo de recompensa.
‚îÇ   ‚îî‚îÄ‚îÄ logger.py      # EpisodeLogger. Salva CSVs com metadados por epis√≥dio.
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ robots/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ robot_stage1.xacro      # Rob√¥ inicial (2 DOF por perna).
‚îÇ   ‚îî‚îÄ‚îÄ environments/
‚îÇ       ‚îî‚îÄ‚îÄ PR.xacro                # Ambiente Plano Regular (implementado).
‚îú‚îÄ‚îÄ tmp/                            # URDFs gerados em tempo de execu√ß√£o.
‚îî‚îÄ‚îÄ logs/
    ‚îú‚îÄ‚îÄ training_log.txt            # Log principal da aplica√ß√£o.
    ‚îî‚îÄ‚îÄ data/                       # CSVs com metadados de cada epis√≥dio.

### Cronograma Implementado

Funda√ß√£o: Avatar, Ambiente PR, Agente Aleat√≥rio.
Rob√¥ se move alguns cm antes de cair.

Valida√ß√£o do Pipeline: GUI, Gr√°ficos, Logging, CSV.
Interface funcional, dados salvos corretamente.

‚û°Ô∏è Pr√≥ximo
Primeiro Treinamento com RL (PPO).
Rob√¥ completa 10m com >10% de sucesso.

‚û°Ô∏è Pr√≥ximo
Ajuste de Par√¢metros e Primeiros Resultados Estat√≠sticos.
/PR.csv
com Tm, œÉ-Tm, sucesso.

‚û°Ô∏è Futuro
Testar Generaliza√ß√£o: Criar novos ambientes, treinar 6 AEs.
Avalia√ß√£o cruzada, c√°lculo de ŒîTm.

‚û°Ô∏è Futuro
An√°lise de Resultados e Elabora√ß√£o de Tese.
Gr√°ficos, conclus√µes sobre generaliza√ß√£o.

### Licen√ßa
Este projeto √© de uso acad√™mico. Para mais detalhes, consulte o arquivo LICENSE.