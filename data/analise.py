import pandas as pd
import numpy as np
import scipy.stats as stats
from scipy.stats import f_oneway, levene
from scipy.stats import f as f_dist
import os
import warnings
from openpyxl import Workbook, load_workbook
from openpyxl.styles import Font, Alignment
from openpyxl.utils import get_column_letter
import datetime
import locale

# Configurar locale para Portugu√™s Brasil
try:
    locale.setlocale(locale.LC_ALL, 'pt_BR.UTF-8')
except:
    try:
        locale.setlocale(locale.LC_ALL, 'Portuguese_Brazil.1252')
    except:
        pass

warnings.filterwarnings('ignore')

try:
    from statsmodels.stats.multicomp import pairwise_tukeyhsd
    STATSMODELS_AVAILABLE = True
except ImportError:
    STATSMODELS_AVAILABLE = False

# Fun√ß√µes auxiliares para ANOVA de Welch e Games-Howell
def welch_anova(data_groups):
    """
    Realiza ANOVA de Welch (para vari√¢ncias heterog√™neas)
    Retorna: F, df1, df2, p_value
    """
    k = len(data_groups)
    
    # Calcular m√©dias e vari√¢ncias
    means = [np.mean(g) for g in data_groups]
    vars_ = [np.var(g, ddof=1) for g in data_groups]
    ns = [len(g) for g in data_groups]
    
    # Pesos
    w = [n/v for n, v in zip(ns, vars_)]
    
    # M√©dia ponderada
    mean_w = np.sum([w[i]*means[i] for i in range(k)]) / np.sum(w)
    
    # Estat√≠stica F de Welch
    A = np.sum([w[i]*(means[i] - mean_w)**2 for i in range(k)])
    B = 2*(k-2) / (k**2 - 1) * np.sum([(1 - w[i]/np.sum(w))**2 / (ns[i]-1) for i in range(k)])
    
    F = A / (k-1) / (1 + B)
    
    # Graus de liberdade
    df1 = k - 1
    df2 = 1 / (3 * np.sum([(1 - w[i]/np.sum(w))**2 / (ns[i]-1) for i in range(k)]))
    
    # Valor p
    p_value = 1 - f_dist.cdf(F, df1, df2)
    
    return F, df1, df2, p_value

def games_howell(data_groups, group_names):
    """
    Realiza teste post-hoc de Games-Howell para vari√¢ncias heterog√™neas
    """
    results = []
    k = len(data_groups)
    
    for i in range(k):
        for j in range(i+1, k):
            # Dados dos dois grupos
            data_i = data_groups[i]
            data_j = data_groups[j]
            
            # Estat√≠sticas b√°sicas
            n_i = len(data_i)
            n_j = len(data_j)
            mean_i = np.mean(data_i)
            mean_j = np.mean(data_j)
            var_i = np.var(data_i, ddof=1)
            var_j = np.var(data_j, ddof=1)
            
            # Diferen√ßa das m√©dias
            diff = mean_i - mean_j
            
            # Erro padr√£o
            se = np.sqrt(var_i/n_i + var_j/n_j)
            
            # Graus de liberdade (Welch-Satterthwaite)
            df = (var_i/n_i + var_j/n_j)**2 / ((var_i/n_i)**2/(n_i-1) + (var_j/n_j)**2/(n_j-1))
            
            # Estat√≠stica t
            t = diff / se
            
            # Valor p (bicaudal)
            p = 2 * (1 - stats.t.cdf(abs(t), df))
            
            # Intervalo de confian√ßa 95%
            t_crit = stats.t.ppf(0.975, df)
            ci_lower = diff - t_crit * se
            ci_upper = diff + t_crit * se
            
            results.append({
                'Grupo 1': group_names[i],
                'Grupo 2': group_names[j],
                'M√©dia 1': mean_i,
                'M√©dia 2': mean_j,
                'Diferen√ßa': diff,
                'Erro Padr√£o': se,
                'IC 95% Inferior': ci_lower,
                'IC 95% Superior': ci_upper,
                't': t,
                'df': df,
                'p-valor': p,
                'Significativo': p < 0.05,
                'Tipo': 'Games-Howell'
            })
    
    return results

def formatar_numero_br(valor, casas_decimais=4):
    """Formata n√∫meros no formato brasileiro (v√≠rgula como separador decimal)"""
    if pd.isna(valor):
        return "N/A"
    
    try:
        # Formatar com v√≠rgula como separador decimal
        formato = f"{{:,.{casas_decimais}f}}"
        numero_formatado = formato.format(float(valor))
        # Substituir ponto por v√≠rgula
        return numero_formatado.replace('.', ',')
    except:
        return str(valor)

def formatar_pvalor_br(valor):
    """Formata p-valores no formato brasileiro"""
    if pd.isna(valor):
        return "N/A"
    
    try:
        valor_float = float(valor)
        if valor_float < 0.001:
            return "< 0,001"
        elif valor_float < 0.01:
            return f"{valor_float:.3f}".replace('.', ',')
        else:
            return f"{valor_float:.4f}".replace('.', ',')
    except:
        return str(valor)

def analisar_dataframe_completo(df, nome_arquivo):
    """Analisa um DataFrame e retorna todos os resultados detalhados seguindo o fluxo especificado"""
    resultados_detalhados = []
    resultados_posthoc_completo = []
    
    # Limpeza dos dados
    df = df.dropna(axis=1, how='all')
    df.columns = df.columns.str.strip()
    
    # Identificar colunas num√©ricas (ignorando identificadores)
    padroes_ignorar = ['epis√≥dio', 'episodio', 'episode', 'id', 'codigo', 'c√≥digo', 'code']
    colunas_numericas = []
    
    for coluna in df.columns:
        coluna_lower = str(coluna).strip().lower()
        ignorar = any(padrao in coluna_lower for padrao in padroes_ignorar)
        
        if not ignorar:
            try:
                dados_convertidos = pd.to_numeric(df[coluna].astype(str).str.replace(',', '.'), errors='coerce')
                if dados_convertidos.notna().sum() / len(dados_convertidos) >= 0.5:
                    colunas_numericas.append(coluna)
            except:
                continue
    
    if not colunas_numericas:
        return {
            'estatisticas': [],
            'comparacoes': [],
            'posthoc': [],
            'correlacoes': []
        }
    
    # Converter apenas as colunas num√©ricas
    for coluna in colunas_numericas:
        df[coluna] = pd.to_numeric(df[coluna].astype(str).str.replace(',', '.'), errors='coerce')
    
    # Identificar colunas v√°lidas (com pelo menos 3 observa√ß√µes)
    colunas_validas = [col for col in colunas_numericas if len(df[col].dropna()) >= 3]
    
    if len(colunas_validas) < 1:
        return {
            'estatisticas': [],
            'comparacoes': [],
            'posthoc': [],
            'correlacoes': []
        }
    
    # --- SE√á√ÉO 1: ESTAT√çSTICAS DESCRITIVAS COMPLETAS ---
    estatisticas_detalhadas = []
    for coluna in colunas_validas:
        dados = df[coluna].dropna()
        
        # Para amostras grandes (>100), usar intervalo de confian√ßa baseado na distribui√ß√£o normal
        n = len(dados)
        if n > 0:
            mean_val = dados.mean()
            std_val = dados.std()
            se = std_val / np.sqrt(n)
            
            # Para n > 30, usar distribui√ß√£o normal; para n <= 30, usar t-student
            if n > 30:
                ci_lower = mean_val - 1.96 * se
                ci_upper = mean_val + 1.96 * se
            else:
                t_crit = stats.t.ppf(0.975, n-1)
                ci_lower = mean_val - t_crit * se
                ci_upper = mean_val + t_crit * se
        else:
            mean_val = std_val = se = ci_lower = ci_upper = np.nan
        
        estatisticas = {
            'Arquivo': nome_arquivo,
            'Vari√°vel': coluna,
            'Tipo': 'Estat√≠stica Descritiva',
            'M√©dia': mean_val,
            'DP': std_val,
            'Mediana': dados.median(),
            'IC 95% Inferior': ci_lower,
            'IC 95% Superior': ci_upper,
            'M√≠nimo': dados.min(),
            'M√°ximo': dados.max(),
            'CV (%)': (std_val / mean_val * 100) if mean_val != 0 else np.nan,
            'N': n
        }
        estatisticas_detalhadas.append(estatisticas)
    
    # --- SE√á√ÉO 2: COMPARA√á√ÉO ENTRE GRUPOS (FLUXO ESPECIFICADO) ---
    comparacoes_grupos = []
    
    if len(colunas_validas) >= 2:
        grupos_dados = [df[col].dropna().values for col in colunas_validas]
        N_total = sum(len(g) for g in grupos_dados)
        k = len(grupos_dados)
        
        # TESTE DE LEVENE (Homogeneidade de vari√¢ncias)
        try:
            stat_levene, p_levene = levene(*grupos_dados)
            homogeneo = p_levene >= 0.05  # p ‚â• 0.05 = homog√™neo, p < 0.05 = n√£o homog√™neo
            
            comparacoes_grupos.append({
                'Arquivo': nome_arquivo,
                'Vari√°vel': 'Todas',
                'Tipo': 'Homogeneidade',
                'Teste': 'Levene',
                'Estat√≠stica': stat_levene,
                'p-valor': p_levene,
                'Resultado': 'Homog√™neas' if homogeneo else 'N√£o Homog√™neas',
                'Decis√£o': 'ANOVA Cl√°ssica + Tukey' if homogeneo else 'ANOVA Welch + Games-Howell'
            })
            
            # FLUXO DECISIONAL BASEADO NO LEVENE
            if homogeneo:  # p ‚â• 0,05
                # ANOVA CL√ÅSSICA
                try:
                    f_stat, p_anova = f_oneway(*grupos_dados)
                    df_between = k - 1
                    df_within = N_total - k
                    
                    if df_within > 0:
                        comparacoes_grupos.append({
                            'Arquivo': nome_arquivo,
                            'Vari√°vel': 'ANOVA',
                            'Tipo': 'Compara√ß√£o',
                            'Teste': 'ANOVA Cl√°ssica',
                            'Estat√≠stica': f_stat,
                            'gl entre': df_between,
                            'gl dentro': df_within,
                            'p-valor': p_anova,
                            'Resultado': 'Significativa' if p_anova < 0.05 else 'N√£o Significativa',
                            'Decis√£o': 'Prosseguir com Tukey HSD' if p_anova < 0.05 else 'N√£o necess√°rio'
                        })
                        
                        # TUKEY HSD (apenas se ANOVA for significativa)
                        if p_anova < 0.05 and STATSMODELS_AVAILABLE:
                            try:
                                tukey_data = []
                                tukey_groups = []
                                
                                for i, dados in enumerate(grupos_dados):
                                    tukey_data.extend(dados)
                                    tukey_groups.extend([colunas_validas[i]] * len(dados))
                                
                                tukey_result = pairwise_tukeyhsd(tukey_data, tukey_groups, alpha=0.05)
                                
                                if hasattr(tukey_result, 'summary') and tukey_result.summary() is not None:
                                    for i in range(len(tukey_result.summary().data) - 1):
                                        row = tukey_result.summary().data[i + 1]
                                        if len(row) > 6:
                                            comparacao = {
                                                'Arquivo': nome_arquivo,
                                                'Grupo 1': str(row[0]),
                                                'Grupo 2': str(row[1]),
                                                'M√©dia 1': df[colunas_validas[colunas_validas.index(str(row[0]))]].mean() if str(row[0]) in colunas_validas else np.nan,
                                                'M√©dia 2': df[colunas_validas[colunas_validas.index(str(row[1]))]].mean() if str(row[1]) in colunas_validas else np.nan,
                                                'Diferen√ßa': float(row[2]),
                                                'Erro Padr√£o': float(row[3]),
                                                'IC 95% Inferior': float(row[4]),
                                                'IC 95% Superior': float(row[5]),
                                                'p-valor': float(row[6]) if len(row) > 6 else np.nan,
                                                'Significativo': bool(row[7]) if len(row) > 7 else False,
                                                'Tipo': 'Tukey HSD'
                                            }
                                            resultados_posthoc_completo.append(comparacao)
                            except Exception as e:
                                resultados_posthoc_completo.append({
                                    'Arquivo': nome_arquivo,
                                    'Grupo 1': 'Erro',
                                    'Grupo 2': str(e)[:50],
                                    'Tipo': 'Erro Tukey'
                                })
                except Exception as e:
                    comparacoes_grupos.append({
                        'Arquivo': nome_arquivo,
                        'Vari√°vel': 'ANOVA',
                        'Tipo': 'Compara√ß√£o',
                        'Teste': 'ANOVA Cl√°ssica (Erro)',
                        'Estat√≠stica': np.nan,
                        'gl entre': np.nan,
                        'gl dentro': np.nan,
                        'p-valor': np.nan,
                        'Resultado': f'Erro: {str(e)[:50]}'
                    })
            
            else:  # p < 0,05
                # ANOVA DE WELCH
                try:
                    F_welch, df1_welch, df2_welch, p_welch = welch_anova(grupos_dados)
                    
                    comparacoes_grupos.append({
                        'Arquivo': nome_arquivo,
                        'Vari√°vel': 'ANOVA',
                        'Tipo': 'Compara√ß√£o',
                        'Teste': 'ANOVA de Welch',
                        'Estat√≠stica': F_welch,
                        'gl entre': df1_welch,
                        'gl dentro': df2_welch,
                        'p-valor': p_welch,
                        'Resultado': 'Significativa' if p_welch < 0.05 else 'N√£o Significativa',
                        'Decis√£o': 'Prosseguir com Games-Howell' if p_welch < 0.05 else 'N√£o necess√°rio'
                    })
                    
                    # GAMES-HOWELL (apenas se ANOVA de Welch for significativa)
                    if p_welch < 0.05:
                        try:
                            gh_results = games_howell(grupos_dados, colunas_validas)
                            for gh in gh_results:
                                gh['Arquivo'] = nome_arquivo
                                resultados_posthoc_completo.append(gh)
                        except Exception as e:
                            resultados_posthoc_completo.append({
                                'Arquivo': nome_arquivo,
                                'Grupo 1': 'Erro',
                                'Grupo 2': str(e)[:50],
                                'Tipo': 'Erro Games-Howell'
                            })
                except Exception as e:
                    comparacoes_grupos.append({
                        'Arquivo': nome_arquivo,
                        'Vari√°vel': 'ANOVA',
                        'Tipo': 'Compara√ß√£o',
                        'Teste': 'ANOVA de Welch (Erro)',
                        'Estat√≠stica': np.nan,
                        'gl entre': np.nan,
                        'gl dentro': np.nan,
                        'p-valor': np.nan,
                        'Resultado': f'Erro: {str(e)[:50]}'
                    })
        
        except Exception as e:
            comparacoes_grupos.append({
                'Arquivo': nome_arquivo,
                'Vari√°vel': 'Todas',
                'Tipo': 'Homogeneidade',
                'Teste': 'Levene',
                'Estat√≠stica': np.nan,
                'p-valor': np.nan,
                'Resultado': f'Erro: {str(e)[:50]}'
            })
    
    # --- SE√á√ÉO 3: MATRIZ DE CORRELA√á√ÉO (Pearson) ---
    matriz_correlacao = []
    if len(colunas_validas) >= 2:
        # Calcular correla√ß√£o de Pearson
        df_corr = df[colunas_validas].corr()
        
        for i in range(len(colunas_validas)):
            for j in range(i+1, len(colunas_validas)):
                var1 = colunas_validas[i]
                var2 = colunas_validas[j]
                corr = df_corr.loc[var1, var2]
                
                # Teste de signific√¢ncia da correla√ß√£o
                n = len(df[[var1, var2]].dropna())
                if n > 2:
                    t_stat = corr * np.sqrt((n-2)/(1-corr**2)) if abs(corr) < 1 else np.nan
                    p_corr = 2 * (1 - stats.t.cdf(abs(t_stat), n-2)) if not pd.isna(t_stat) else np.nan
                else:
                    p_corr = np.nan
                
                matriz_correlacao.append({
                    'Arquivo': nome_arquivo,
                    'Vari√°vel 1': var1,
                    'Vari√°vel 2': var2,
                    'Correla√ß√£o (r)': corr,
                    'r¬≤': corr**2,
                    'p-valor': p_corr,
                    'n': n,
                    'Interpreta√ß√£o': interpretar_correlacao(corr),
                    'Tipo': 'Correla√ß√£o'
                })
    
    return {
        'estatisticas': estatisticas_detalhadas,
        'comparacoes': comparacoes_grupos,
        'posthoc': resultados_posthoc_completo,
        'correlacoes': matriz_correlacao
    }

def interpretar_correlacao(r):
    """Interpreta o valor da correla√ß√£o"""
    if pd.isna(r):
        return "N/A"
    
    r_abs = abs(r)
    if r_abs >= 0.9:
        return "Muito forte"
    elif r_abs >= 0.7:
        return "Forte"
    elif r_abs >= 0.5:
        return "Moderada"
    elif r_abs >= 0.3:
        return "Fraca"
    elif r_abs >= 0.1:
        return "Muito fraca"
    else:
        return "Desprez√≠vel"

def criar_excel_por_arquivo(arquivos_resultados):
    """Cria um Excel com uma aba para cada arquivo CSV"""
    
    wb = Workbook()
    
    # Remover aba padr√£o
    wb.remove(wb.active)
    
    # Criar aba de √≠ndice
    ws_indice = wb.create_sheet(title="√çNDICE")
    ws_indice.append(["RELAT√ìRIO DE AN√ÅLISE ESTAT√çSTICA"])
    ws_indice.append([f"Gerado em: {datetime.datetime.now().strftime('%d/%m/%Y %H:%M:%S')}"])
    ws_indice.append([])
    ws_indice.append(["Arquivo", "Vari√°veis", "Observa√ß√µes", "Teste ANOVA", "p-valor ANOVA", "Teste Post-Hoc", "Aba"])
    
    for nome_arquivo, resultados in arquivos_resultados.items():
        # Criar aba para este arquivo
        nome_aba = nome_arquivo[:31]  # Excel limita a 31 caracteres
        ws = wb.create_sheet(title=nome_aba)
        
        # --- CABE√áALHO DA ABA ---
        ws.append([f"AN√ÅLISE ESTAT√çSTICA: {nome_arquivo}"])
        ws.append([f"Data: {datetime.datetime.now().strftime('%d/%m/%Y %H:%M')}"])
        ws.append([])
        
        # --- 1. ESTAT√çSTICAS DESCRITIVAS ---
        ws.append(["1. ESTAT√çSTICAS DESCRITIVAS"])
        ws.append(["Vari√°vel", "M√©dia", "DP", "Mediana", 
                  "IC 95% Inferior", "IC 95% Superior", "M√≠nimo", "M√°ximo", 
                  "CV (%)"])
        
        for estat in resultados['estatisticas']:
            ws.append([
                estat['Vari√°vel'],
                formatar_numero_br(estat['M√©dia']),
                formatar_numero_br(estat['DP']),
                formatar_numero_br(estat['Mediana']),
                formatar_numero_br(estat['IC 95% Inferior']),
                formatar_numero_br(estat['IC 95% Superior']),
                formatar_numero_br(estat['M√≠nimo']),
                formatar_numero_br(estat['M√°ximo']),
                formatar_numero_br(estat['CV (%)'], 1) if not pd.isna(estat['CV (%)']) else "N/A"
            ])
        
        ws.append([])
        ws.append([])
        
        # --- 2. AN√ÅLISE DE HOMOGENEIDADE - TESTE DE LEVENE ---
        if resultados['comparacoes']:
            # Encontrar resultado do Levene
            levene_results = [c for c in resultados['comparacoes'] if c.get('Teste') == 'Levene']
            if levene_results:
                ws.append(["2. TESTE DE LEVENE"])
                ws.append(["Estat√≠stica F", "p-valor", "Resultado"])
                
                for levene in levene_results:
                    ws.append([
                        formatar_numero_br(levene['Estat√≠stica']),
                        formatar_pvalor_br(levene['p-valor']),
                        levene['Resultado']
                    ])
                
                ws.append([])
                ws.append([])
                
                # --- 3. ANOVA ---
                anova_results = [c for c in resultados['comparacoes'] if 'ANOVA' in c.get('Teste', '')]
                for anova in anova_results:
                    if 'Cl√°ssica' in anova['Teste']:
                        ws.append(["3. ANOVA CL√ÅSSICA"])
                    elif 'Welch' in anova['Teste']:
                        ws.append(["3. ANOVA DE WELCH"])
                    else:
                        ws.append(["3. ANOVA"])
                    
                    ws.append(["F", "gl entre", "gl dentro", "p-valor", "Resultado"])
                    ws.append([
                        formatar_numero_br(anova['Estat√≠stica']),
                        formatar_numero_br(anova.get('gl entre', np.nan), 0),
                        formatar_numero_br(anova.get('gl dentro', np.nan), 0),
                        formatar_pvalor_br(anova['p-valor']),
                        anova['Resultado']
                    ])
                    
                    ws.append([])
                    ws.append([])
                    
                    # --- 4. TESTE POST-HOC ---
                    if resultados['posthoc']:
                        posthoc_tipo = 'Tukey HSD' if 'Tukey' in str(resultados['posthoc'][0].get('Tipo', '')) else 'Games-Howell'
                        ws.append([f"4. TESTE POST-HOC - {posthoc_tipo}"])
                        
                        # Filtrar apenas resultados v√°lidos
                        valid_posthoc = [p for p in resultados['posthoc'] if 'Erro' not in str(p.get('Tipo', ''))]
                        
                        if valid_posthoc:
                            ws.append(["Grupo 1", "Grupo 2", "Diferen√ßa", "Erro Padr√£o", 
                                      "IC 95% Inferior", "IC 95% Superior", "p-valor", "Significativo"])
                            
                            for posthoc in valid_posthoc:
                                ws.append([
                                    posthoc['Grupo 1'],
                                    posthoc['Grupo 2'],
                                    formatar_numero_br(posthoc.get('Diferen√ßa', np.nan)),
                                    formatar_numero_br(posthoc.get('Erro Padr√£o', np.nan)),
                                    formatar_numero_br(posthoc.get('IC 95% Inferior', np.nan)),
                                    formatar_numero_br(posthoc.get('IC 95% Superior', np.nan)),
                                    formatar_pvalor_br(posthoc.get('p-valor', np.nan)),
                                    "SIM" if posthoc.get('Significativo', False) else "N√ÉO"
                                ])
                        else:
                            ws.append(["N√£o foram encontradas compara√ß√µes post-hoc v√°lidas"])
                        
                        ws.append([])
                        ws.append([])

        # Formatar esta aba
        formatar_aba_excel(ws)
        
        # Adicionar ao √≠ndice
        var_count = len(resultados['estatisticas'])
        obs_count = sum(estat['N'] for estat in resultados['estatisticas'])
        
        # Determinar teste ANOVA usado
        teste_anova = "N/A"
        p_anova = "N/A"
        teste_posthoc = "Nenhum"
        
        for comp in resultados['comparacoes']:
            if 'ANOVA' in comp.get('Teste', ''):
                teste_anova = comp['Teste']
                p_anova = formatar_pvalor_br(comp['p-valor'])
                break
        
        if resultados['posthoc']:
            if any('Tukey' in str(p.get('Tipo', '')) for p in resultados['posthoc']):
                teste_posthoc = "Tukey HSD"
            elif any('Games' in str(p.get('Tipo', '')) for p in resultados['posthoc']):
                teste_posthoc = "Games-Howell"
        
        ws_indice.append([
            nome_arquivo,
            var_count,
            obs_count,
            teste_anova,
            p_anova,
            teste_posthoc,
            nome_aba
        ])
    
    # Formatar aba de √≠ndice
    formatar_aba_excel(ws_indice)
    
    # Salvar arquivo
    nome_excel = 'Analise_Estatistica.xlsx'
    wb.save(nome_excel)
    
    return nome_excel

def formatar_aba_excel(ws):
    """Aplica formata√ß√£o personalizada a uma aba - sem sombreamento, sem bordas"""
    # Definir estilos
    fonte_normal = Font(name='Arial', size=10, color='000000')
    fonte_negrito = Font(name='Arial', size=10, bold=True, color='000000')
    fonte_titulo = Font(name='Arial', size=12, bold=True, color='000000')
    
    # Aplicar estilos
    for row in ws.iter_rows():
        for cell in row:
            cell.font = fonte_normal
            
            # C√©lula vazia ou sem valor
            if cell.value is None:
                continue
            
            # T√≠tulo principal (linha 1)
            if cell.row == 1:
                cell.font = fonte_titulo
                cell.alignment = Alignment(horizontal='center', vertical='center')
            
            # T√≠tulos das se√ß√µes (linhas que come√ßam com n√∫mero)
            elif isinstance(cell.value, str) and cell.column == 1:
                if (cell.value.startswith("1.") or 
                    cell.value.startswith("2.") or 
                    cell.value.startswith("3.") or 
                    cell.value.startswith("4.") or 
                    cell.value.startswith("5.")):
                    cell.font = fonte_negrito
            
            # Cabe√ßalhos de tabela (linha ap√≥s t√≠tulo da se√ß√£o)
            elif cell.row > 1:
                # Verificar se √© cabe√ßalho de tabela
                row_vals = [ws.cell(row=cell.row, column=c).value for c in range(1, ws.max_column + 1)]
                non_empty = sum(1 for val in row_vals if val and str(val).strip())
                
                # Se a linha tem muitos valores (provavelmente √© cabe√ßalho)
                if non_empty > 2 and cell.row < ws.max_row:
                    # Verificar se a linha anterior era t√≠tulo de se√ß√£o
                    prev_row_val = ws.cell(row=cell.row-1, column=1).value
                    if prev_row_val and any(prev_row_val.startswith(f"{i}.") for i in range(1, 6)):
                        cell.font = fonte_negrito
                        cell.alignment = Alignment(horizontal='center', vertical='center')
    
    # Ajustar largura das colunas
    for column in ws.columns:
        max_length = 0
        column_letter = get_column_letter(column[0].column)
        
        for cell in column:
            try:
                if cell.value:
                    max_length = max(max_length, len(str(cell.value)))
            except:
                pass
        
        adjusted_width = min(max_length + 2, 30)
        ws.column_dimensions[column_letter].width = adjusted_width

def processar_todos_csv():
    """Processa todos os arquivos CSV na pasta"""
    
    # Listar arquivos CSV
    arquivos_csv = [f for f in os.listdir('.') 
                   if f.lower().endswith('.csv') 
                   and not f.startswith('Analise_Estatistica_')]
    
    if not arquivos_csv:
        print("‚úó Nenhum arquivo CSV encontrado na pasta.")
        return
    
    print(f"üîç Encontrados {len(arquivos_csv)} arquivo(s) CSV")
    print("-" * 50)
    
    arquivos_resultados = {}
    
    for arquivo in arquivos_csv:
        try:
            print(f"üìä Processando: {arquivo}")
            
            # Tentar diferentes encodings
            df = None
            encoding_usado = None
            
            for encoding in ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1', 'utf-8-sig']:
                try:
                    df = pd.read_csv(arquivo, sep=',', decimal=',', encoding=encoding)
                    encoding_usado = encoding
                    break
                except UnicodeDecodeError:
                    continue
                except Exception:
                    continue
            
            if df is None:
                # √öltima tentativa
                try:
                    df = pd.read_csv(arquivo, sep=',', decimal=',', engine='python')
                    encoding_usado = 'python engine'
                except Exception as e:
                    print(f"  ‚úó Erro na leitura: {str(e)[:50]}")
                    continue
            
            print(f"  ‚úì Encoding: {encoding_usado}")
            print(f"  ‚úì Formato: {df.shape[0]} linhas √ó {df.shape[1]} colunas")
            
            # Analisar o DataFrame
            resultados = analisar_dataframe_completo(df, arquivo)
            arquivos_resultados[arquivo] = resultados
            
            # Mostrar resumo r√°pido
            var_count = len(resultados['estatisticas'])
            print(f"  ‚úì Vari√°veis analisadas: {var_count}")
            
            # Mostrar decis√£o do teste
            for comp in resultados['comparacoes']:
                if comp.get('Teste') == 'Levene':
                    print(f"  ‚úì Levene: {comp.get('Resultado', 'N/A')}")
                    print(f"  ‚úì Decis√£o: {comp.get('Decis√£o', 'N/A')}")
                elif 'ANOVA' in comp.get('Teste', ''):
                    print(f"  ‚úì {comp['Teste']}: {comp.get('Resultado', 'N/A')}")
            
            print()
            
        except Exception as e:
            print(f"  ‚úó Erro no processamento: {str(e)[:50]}")
            print()
            continue
    
    if arquivos_resultados:
        # Criar Excel com todas as abas
        excel_file = criar_excel_por_arquivo(arquivos_resultados)
        print(f"\n‚úÖ An√°lise conclu√≠da!")
        print(f"üìÅ Arquivo Excel gerado: {excel_file}")
        print(f"üìä Total de arquivos analisados: {len(arquivos_resultados)}")
        return excel_file
    else:
        print("\n‚ùå Nenhum arquivo p√¥de ser analisado.")
        return None

if __name__ == "__main__":
    print("=" * 70)
    print("üìà SISTEMA DE AN√ÅLISE ESTAT√çSTICA")
    print("=" * 70)
    print("FLUXO ESTAT√çSTICO:")
    print("1. ESTAT√çSTICAS DESCRITIVAS")
    print("2. Teste de Levene (Homogeneidade)")
    print("   - Se p ‚â• 0,05 ‚Üí ANOVA Cl√°ssica + Tukey")
    print("   - Se p < 0,05 ‚Üí ANOVA Welch + Games-Howell")
    print("3. Correla√ß√£o de Pearson")
    print("\nESTAT√çSTICAS PARA N > 100:")
    print("‚Ä¢ Intervalo de Confian√ßa baseado na distribui√ß√£o normal")
    print("‚Ä¢ Teste de Levene robusto para grandes amostras")
    print("‚Ä¢ ANOVA v√°lida devido ao Teorema do Limite Central")
    print("-" * 50)
    
    print("‚öôÔ∏è  Verificando depend√™ncias...")
    
    # Verificar depend√™ncias
    try:
        import openpyxl
        print("  ‚úì Openpyxl: OK")
    except:
        print("  ‚úó Openpyxl n√£o instalado. Instale: pip install openpyxl")
        exit()
    
    if STATSMODELS_AVAILABLE:
        print("  ‚úì Statsmodels: OK (Tukey dispon√≠vel)")
    else:
        print("  ‚ö†Ô∏è  Statsmodels n√£o instalado. Tukey n√£o dispon√≠vel.")
        print("      Instale: pip install statsmodels")
    
    print("\n" + "-" * 50)
    print("Iniciando processamento...\n")
    
    processar_todos_csv()